{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2_0e_U3Unyj"
      },
      "source": [
        "# HW8 (70 points total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHMpS_vL32rv"
      },
      "source": [
        "# Problem 1:   Forwarding the mail (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgaNY8Ie32rw"
      },
      "source": [
        "There's just one email address for *Handy Home Helpers*, but there are three kinds of things the business does, each of which is handled by a different associate.  Alice handles bathroom work - clogged toilets and drains, mold removal, leaks.  Bob handles HVAC work - air conditioning and heating, mostly.  Chun does appliance repair:  dishwashers, washers, driers.  They'd like to have a script that can forward emails sent to the main address to the right associate.\n",
        "\n",
        "Write a function *forward(text, wv)* that reads the email *text* and returns the email address of the associate to whom the email should be forwarded (\"alice@hhh.com\", \"bob@hhh.com\", or \"chun@hhh.com\").  To do this, your code should create a vector for each associate that represents their interests overall, and return the email of the associate whose vector is closest in angle to the vector of the email.  Use *find_avg_word_vector()* and *find_cosine()* from lecture, and make use of the provided topic strings.  Break ties among the associates alphabetically, so for example Alice gets the mail if she's tied for closest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4PIA38232rw"
      },
      "outputs": [],
      "source": [
        "alice = 'bathrooom toilet clogged drain mold leaks'\n",
        "bob = 'air-conditioning AC heating cooling vents air'\n",
        "chun = 'appliances dishwashers washer drier repair'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FPz1DaP32rx"
      },
      "outputs": [],
      "source": [
        "# May need to !pip install gensim if working locally\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJFYJxIj32rx"
      },
      "outputs": [],
      "source": [
        "# TODO:  get relevant functions from lecture notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEW46Yxh32rx"
      },
      "outputs": [],
      "source": [
        "# TODO: forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bvbF-TT32rx"
      },
      "outputs": [],
      "source": [
        "# Test1: Expect 'alice@hhh.com'\n",
        "test1 = \"Tried a plunger and no luck.  Help!\"\n",
        "forward(test1, wv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4W6NcXP32ry"
      },
      "outputs": [],
      "source": [
        "#Test2: Expect 'bob@hhh.com'\n",
        "test2 = \"So hot - I think the thermostat is busted...\"\n",
        "forward(test2, wv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-gwIth32ry"
      },
      "outputs": [],
      "source": [
        "#Test3: Expect 'chun@hhh.com'\n",
        "test3 = \"I need to fix my dishwasher - suds flood the kitchen every time I run it\"\n",
        "forward(test3, wv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UejFMr32ry"
      },
      "source": [
        "# Problem 2:  Price of Milk Interpolation (7 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rCwt68c32ry"
      },
      "source": [
        "The following y values represent the average price of a gallon of milk for each year. (Source: https://www.usinflationcalculator.com/inflation/milk-prices-adjusted-for-inflation/) Perform linear regression with scikit-learn's LinearRegression class.  Then plot the points alongside the linear fit.  And finally, make a prediction for 2023 with this linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX1xT2zd32ry"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.linspace(1995, 2021, 27)\n",
        "y = [2.48, 2.62, 2.61, 2.70, 2.84,\n",
        "     2.78, 2.88, 2.76, 2.76, 3.16, 3.19, 3.08, 3.50, 3.80, 3.11,\n",
        "     3.26, 3.57, 3.49, 3.46, 3.69, 3.42, 3.20, 3.23, 2.90, 3.04,\n",
        "     3.32, 3.55]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuIQYIYQ32rz"
      },
      "outputs": [],
      "source": [
        "# TODO linear regression and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRdPblBt32rz"
      },
      "outputs": [],
      "source": [
        "# TODO: Prediction for 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0aLNzlk32rz"
      },
      "source": [
        "# Problem 3:  Cumulative problems (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2t_4eaM32rz"
      },
      "source": [
        "a (20 points):  Suppose we have a matrix where the $m$ rows represent different observations and the $n$ columns represent different features of the same example.  We also have an $(m-v)$-element 1D numpy array of labels for the training examples, 0 or 1, and a $v$ element numpy array with labels for the validation examples (which all come after the training examples in the feature matrix).  We'd like to train a bunch of decision trees, checking what happens when we train with all possible combinations of the following constructor parameters:  max_depth (2, 10, or None), min_samples_leaf (1 or 2), and max_features ('sqrt' or None).  The best tree is the one with the highest accuracy on the validation set.  Write a function find_best_params() that tries all combinations of the features and values described above.  Return the validation accuracy of the best tree, the max_depth of the best tree, the min_samples_leaf of the best tree, and the max_features of the best tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCZ_EFg_32rz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Small example for basic testing - things should run\n",
        "examples_example = np.array([[1, 2, 3], [-1, -2, -3], [3, 4, -2], [-6, 4, 1], [1, 2, -4], [1,1,1]])\n",
        "train_labels_example = np.array([1, 0, 1, 0])\n",
        "validation_labels_example = ([0, 1])\n",
        "\n",
        "# Bigger example where params may matter\n",
        "from sklearn.datasets import make_classification\n",
        "big_examples, big_labels = make_classification(n_samples=200, n_features=20, n_classes=2, shuffle=True, random_state=0)\n",
        "big_labels_train = big_labels[:150]\n",
        "big_labels_valid = big_labels[150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUCkmwiu32rz"
      },
      "outputs": [],
      "source": [
        "# TODO: find_best_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKzOXo2H32rz"
      },
      "outputs": [],
      "source": [
        "# With random_state = 0 passed to DecisionTreeClassifier,\n",
        "# accuracy 0.5 - other parameter values depend on order of evaluation\n",
        "find_best_params(examples_example, train_labels_example, validation_labels_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_1az-HW32rz"
      },
      "outputs": [],
      "source": [
        "# With random_state = 0 passed to DecisionTreeClassifier,\n",
        "# Accuracy of 0.9, max_depth varies, min_samples_leaf 1, max_features None\n",
        "find_best_params(big_examples, big_labels_train, big_labels_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czg2YblL32rz"
      },
      "source": [
        "b (15 points):  You are analyzing a long document that happens to mention who reports to who in an organization - for example, \"Mary reports to Alice\".  Write a function print_reports() that analyzes such a string, pulling out all such relationships.  (You can assume the document literally says \"X reports to Y\" with X and Y being the names.). Then print for each person the number of \"direct reports\" that person has, that is, the number of people reporting to them.  (See the tests for examples).  Return the total number of people in the organization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8EUVZlY32rz"
      },
      "outputs": [],
      "source": [
        "# TODO print_reports()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D-0LSI032rz"
      },
      "outputs": [],
      "source": [
        "text = \"Mary reports to Sally, Sally reports to Bob, Bob reports to Alice, \\\n",
        "        but also Yilan reports to Sally, and Medhavi reports to Alice\"\n",
        "# Expect Sally 2, Mary 0, Bob 1, Yilan 0, Medhavi 0, Alice 2\n",
        "# (in no particular order) and return 6\n",
        "print_reports(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVOiPraY32rz"
      },
      "outputs": [],
      "source": [
        "# Don't crash on this\n",
        "text = \"This document has no information\"\n",
        "print_reports(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haEmxEON32r0"
      },
      "outputs": [],
      "source": [
        "# Expect Alice 4, all others 0, total people 5\n",
        "text = \"Bob reports to Alice and Dominique reports to Alice, \\\n",
        "        not to mention Jason reports to Alice and Clive reports to Alice\"\n",
        "print_reports(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqOUvZn32r0"
      },
      "source": [
        "# Problem 4:  Miniproject (20 points + up to 15 points extra credit)\n",
        "\n",
        "This problem has an open-ended component.  You can get full credit by doing the problem set with the *suggested* data set (spotify.csv), but you can get **extra credit** by doing it with a different dataset that you have found on the Internet (for example, on Kaggle.com) and/or doing more analysis than required.  You also have the opportunity to get **additional extra credit applied to your final exam grade** if you are selected to give a lightning talk on Dec 6 about what you found with this project.  The lightning talk is only possible if you chose your own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTlGkdPA32r0"
      },
      "source": [
        "The suggested dataset, guaranteed to have minimal data cleaning but not eligible for extra credit, is the file spotify.csv, which originally came from https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset but which you can now find on Blackboard where you found this assignment.  (For a description of what its features mean, see https://developer.spotify.com/documentation/web-api/reference/get-audio-features.)  We'll assume in the instructions that if you're using that dataset, you're trying to predict genre from the other numerical features.\n",
        "\n",
        "If you choose your own dataset, pick one where you think it would be interesting but feasible to predict some variable in the dataset from the others.  If it needs a lot of \"cleaning\" to be usable, you will get extra credit, but you could also consider looking at a few datasets and picking one that seems somewhat close to directly usable.  (You do *not* need high accuracy in your classifier to get full or extra credit; problems like predicting stock prices from their histories are inherently harder than classifying country from latitude and longitude, for example.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLMrMm9D32r0"
      },
      "source": [
        "a 5 points + 7 points EC) Load the dataset as a DataFrame and prepare it for machine learning.  In the spotify.csv case, we suggest using a sklearn.preprocessing.LabelEncoder to turn the target column into numerical classes; see examples in the documentation (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).  You should also fix any columns that look basically numerical, but for some reason were processed as strings instead; but the suggested dataset doesn't have any of these.\n",
        "\n",
        "If you are cleaning a novel dataset, you may get extra credit here if it takes more work than the spotify dataset to clean.\n",
        "\n",
        "Suggested dataset EC:  For the suggested dataset, you will get better results if you limit the target genres to four easily distinguished categories, such as 'acoustic', 'dance', 'grunge', and 'show-tunes'.  You can use .unique() to see all the categories available in this column.  Choosing your own 4 categories from unique() is worth 1 point of extra credit.  Limiting the classes like this is otherwise optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKxdd_ro32r0"
      },
      "outputs": [],
      "source": [
        "# TODO (may want to break this into several code boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_oSKdtM32r0"
      },
      "source": [
        "b, 7 points) Try predicting your target variable using a RandomForestClassifier from scikit-learn, with all the other numerical features in the dataset as your features.  You can create a dataframe that includes just your numeric features with df.select_dtypes(include='number'), and drop your target (to-be-predicted) column from your features if you need to with df = df.drop(columns=['target']).  (The suggested dataset should also drop the first 'Unnamed' column - that row number predicts the genre number pretty well in that dataset!)  Use a train-test split with 10% of the data in the test set, and evaluate the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6UKIpwQ32r0"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUrYswi332r0"
      },
      "source": [
        "c, 4 points) Choose one argument to RandomForestClassifier besides n_estimators that you vary to try to improve your classifier's accuracy.  (See documentation here:  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)  Train three different classifiers with different values for this parameter, counting the one you already trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDDy4HM132r0"
      },
      "outputs": [],
      "source": [
        "# TODO variation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx8I_sMG32r0"
      },
      "outputs": [],
      "source": [
        "# TODO variation 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1HQz4S32r0"
      },
      "source": [
        "d, 2 points) Use the *_feature_importances* attribute of the RandomForestClassifier to find the relative importances of all your features in your best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSgIrHMk32r0"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCNhodDd32r0"
      },
      "source": [
        "e, up to 8 points EC) In this step, perform some additional analysis of your choice on your dataset, such as looking at correlations, performing statistical tests, or training a different machine learning classifier or regression.  You could also plot data for credit, using scatter plots, bar charts, or other visualizations.  Choose your methods with an eye toward being interesting for step (f).  This step is extra credit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7Nq3fVB32r1"
      },
      "outputs": [],
      "source": [
        "# maybe-TODO anything here:  correlations, statistical tests, other machine learning..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn1V3B7y32r7"
      },
      "source": [
        "f, 2 points plus shot at lightning talk) Look over your findings from parts (a-e) and summarize anything interesting you learned about the data from doing this study.  The students with the best answers to this question (who also chose to analyze novel datasets) may be selected to give lightning talks for additional extra credit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVjVuIe32r7"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MZj0fau32r7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}